{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e1e65d6-3280-4f4a-91af-7f22d770f983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "662e6692-8594-4e34-8193-d85468355cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-10-02 19:00:00')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytz\n",
    "from datetime import datetime, timedelta, date\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Define Argentina's timezone (GMT-3)\n",
    "argentina_tz = pytz.timezone('America/Argentina/Buenos_Aires')\n",
    "\n",
    "# Get the current date and time in Argentina\n",
    "current_time_in_argentina = datetime.now(argentina_tz).replace(minute=0, second=0, microsecond=0).strftime('%Y-%m-%d %H:%M:%S')\n",
    "# Round down (floor) to the nearest hour by setting minutes, seconds, and microseconds to 0\n",
    "current_date = pd.to_datetime(current_time_in_argentina)\n",
    "current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20b0c41b-2edd-481a-a587-b41073c85c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/603286\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Fetching data from 2024-09-19 17:00:00+00:00 to 2024-10-02 18:00:00+00:00\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (2.39s) \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Time-series data is incomplete. Expected 14784 rows, but got 13772. Please ensure the feature pipeline is running properly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minferencesm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_batch_of_features_from_store\n\u001b[1;32m----> 3\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mload_batch_of_features_from_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Create a label encoder object\u001b[39;00m\n\u001b[0;32m      6\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "File \u001b[1;32m~\\Documents\\Proyect\\passenger_flow_predictor\\src\\inferencesm.py:73\u001b[0m, in \u001b[0;36mload_batch_of_features_from_store\u001b[1;34m(current_date)\u001b[0m\n\u001b[0;32m     71\u001b[0m expected_length \u001b[38;5;241m=\u001b[39m n_features \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(station_line_ids)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ts_data) \u001b[38;5;241m!=\u001b[39m expected_length:\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime-series data is incomplete. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ts_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please ensure the feature pipeline is running properly.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Sort data by station, line, and time\u001b[39;00m\n\u001b[0;32m     76\u001b[0m ts_data\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhour_of_entry\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Time-series data is incomplete. Expected 14784 rows, but got 13772. Please ensure the feature pipeline is running properly."
     ]
    }
   ],
   "source": [
    "from src.inferencesm import load_batch_of_features_from_store\n",
    "\n",
    "features = load_batch_of_features_from_store(current_date)\n",
    "\n",
    "# Create a label encoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to 'line' and 'station'\n",
    "features['line'] = label_encoder.fit_transform(features['line'])\n",
    "features['station'] = label_encoder.fit_transform(features['station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b663c-ef86-477a-83b6-1db4f1a02e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8012637-a217-413b-9d40-8159768eca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_registry import get_latest_model_from_registry\n",
    "from src.inferencesm import get_model_predictions\n",
    "\n",
    "model = get_latest_model_from_registry(model_name='subwayBA_passenger_flow_updt', status= 'Production')\n",
    "predictions = get_model_predictions(model, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688a96c-c868-452d-82e5-dcc11d673081",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['hour_of_entry'] = current_date\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46287de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d85b5e-9dca-4018-851f-d354a6186b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_store_api import get_feature_store\n",
    "import src.config as config\n",
    "\n",
    "# connect to the feature group\n",
    "feature_group = get_feature_store().get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_MODEL_PREDICTIONS,\n",
    "    version=1,\n",
    "    description=\"Predictions generated for the next 3 hours by our production model\",\n",
    "    primary_key = ['station', 'line', 'hour_of_entry'],\n",
    "    event_time='hour_of_entry',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb15e4-d02c-4b40-a818-3fad452c9d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['station'] = predictions['station'].astype('int32')\n",
    "predictions['line'] = predictions['line'].astype('int32')\n",
    "print(predictions.dtypes)\n",
    "feature_group.insert(predictions, write_options={\"wait_for_job\": False})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
